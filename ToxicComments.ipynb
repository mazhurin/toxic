{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of Toxic Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle competition: [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, merge, Dot, RepeatVector, Concatenate, Input, Dropout, LSTM, GRU, Activation,GlobalMaxPool1D,Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_embeddings(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec = read_embeddings('./glove/glove.twitter.27B.25d.txt')\n",
    "word_to_vec[\"0.065581\"] = [ 0.39605,  -0.96669,   0.23706,  -0.41379,  -0.97006,   0.16601,  -1.292,\n",
    " -0.58989,   0.11632,  -1.365,    -0.27939,  -0.57222,  -0.97108,  -0.56319,\n",
    " -0.015263, -0.70465,  -0.13867 ,  1.0702 ,  -0.25557  , 0.25122,  -0.87755,\n",
    "  0.70999 ,  0.9118 ,  -0.30077, 0 ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mazhurin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mazhurin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "cache_english_stopwords=stopwords.words('english')\n",
    "\n",
    "replacements = [\n",
    "    ('f u c k', 'fuck'),\n",
    "    ('f uck', 'fuck'),\n",
    "    ('fuckyou', 'fuck you'),\n",
    "    ('fuckmother', 'fuck mother'),\n",
    "    ('WTF', 'what the fuck'),\n",
    "    ('OMFG', 'oh my fucking god'),\n",
    "    ('RTFM', 'read the fucking manual'),\n",
    "    ('ASAFP', 'as soon as fucking possible'),\n",
    "    ('FYVM',  'fuck you very much'),\n",
    "    ('whatever TF', 'whatever the fuck')\n",
    "]\n",
    "\n",
    "bad_words = [\n",
    "    'fuck',\n",
    "    'motherfucker',\n",
    "    'fucker',\n",
    "    'idiot'\n",
    "]\n",
    "\n",
    "def data_clean(message):\n",
    "    for a,b in replacements:\n",
    "        message = message.replace(a, b)\n",
    "    \n",
    "    temp_tw_list = word_tokenize(message)\n",
    "    # Remove stopwords\n",
    "    list_no_stopwords=[i for i in temp_tw_list if i.lower() not in     cache_english_stopwords]\n",
    "    # Remove hyperlinks\n",
    "    list_no_hyperlinks=[re.sub(r'https?:\\/\\/.*\\/\\w*','',i) for i in list_no_stopwords]\n",
    "    # Remove hashtags\n",
    "    list_no_hashtags=[re.sub(r'#', '', i) for i in list_no_hyperlinks]\n",
    "    #Remove numbers\n",
    "    list_no_numbers = [re.sub(r'$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$','', i) for i in list_no_hashtags]\n",
    "   # Remove Punctuation and split 's, 't, 've with a space for filter\n",
    "    list_no_punctuation=[re.sub(r'['+string.punctuation+']+', ' ', i) for i in list_no_numbers]\n",
    "    # Remove multiple whitespace\n",
    "    new_sent = ' '.join(list_no_punctuation)\n",
    "    # Remove any words with 2 or fewer letters\n",
    "    filtered_list = word_tokenize(new_sent)\n",
    "    list_filtered = [re.sub(r'^\\w\\w?$', '', i) for i in filtered_list]\n",
    "    filtered_sent =' '.join(list_filtered)\n",
    "    clean_sent=re.sub(r'\\s\\s+', ' ', filtered_sent)\n",
    "    #Remove any whitespace at the front of the sentence\n",
    "    clean_sent=clean_sent.lstrip(' ')\n",
    "    # remove the articles\n",
    "    clean_sent = re.sub('(\\s+)(a|an|and|the)(\\s+)', ' ', clean_sent)\n",
    "\n",
    "    return clean_sent.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from string import digits\n",
    "def read_comments(filename = ''):\n",
    "    comments = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    remove_punctuation = str.maketrans('', '', string.punctuation)\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "\n",
    "    with open (filename) as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "\n",
    "        header = True\n",
    "        progress = 0\n",
    "        for row in csvReader:\n",
    "            if progress >10000:\n",
    "                break\n",
    "            if progress % 10000 == 0:\n",
    "                print ('Line', progress)\n",
    "            progress += 1\n",
    "            \n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            ids.append(row[0])\n",
    "            #filtered_words = [word for word in s.split() if word not in stopwords.words('english')]\n",
    "            filtered_words = data_clean(row[1]).split()\n",
    "            words = []\n",
    "            for w in filtered_words:\n",
    "                if w in word_to_vec:\n",
    "                    words.append(w)\n",
    "                else:\n",
    "                    for badword in bad_words:\n",
    "                        if badword in w:\n",
    "                            words.append(badword)\n",
    "                            break\n",
    "\n",
    "            comments.append(words)          \n",
    "            if len(row) > 2:\n",
    "                classes = []\n",
    "                for i in range(2,8):\n",
    "                    classes.append(row[i])\n",
    "                labels.append(classes)\n",
    "\n",
    "    ids = np.asarray(ids)\n",
    "    X = np.asarray(comments)\n",
    "    Y = np.asarray(labels, dtype=int)\n",
    "\n",
    "    return ids, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 0\n",
      "Line 10000\n",
      "Line 0\n",
      "Line 10000\n",
      "Max word count = 1233\n"
     ]
    }
   ],
   "source": [
    "id_train, X_train, Y_train = read_comments('./data/train.csv')\n",
    "id_test, X_test, _ = read_comments('./data/test.csv')\n",
    "labels = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "max_comment = 0\n",
    "for i in range(X_train.shape[0]):                               \n",
    "    l = len(X_train[i])\n",
    "    if max_comment < l:\n",
    "        max_comment = l\n",
    "for i in range(X_test.shape[0]):                               \n",
    "    l = len(X_test[i])\n",
    "    if max_comment < l:\n",
    "        max_comment = l\n",
    "num_classes = len(labels)\n",
    "print ('Max word count =', max_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_comment = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5,random_state=seed)\n",
    "folds = list()\n",
    "for train_index, dev_index in kfold.split(X_train):\n",
    "    folds.append({\n",
    "        'train' : train_index,\n",
    "        'dev' : dev_index,     \n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from keras.backend import int_shape\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "_EPSILON = K.epsilon()\n",
    "    \n",
    "def custom_loss(y_true, y_pred):\n",
    "    losses = []\n",
    "    y_pred = K.clip(y_pred, _EPSILON, 1.0-_EPSILON)\n",
    "    num_classes = int_shape(y_pred)[1]\n",
    "    for i in range(num_classes):\n",
    "        losses.append(-K.mean(\n",
    "            y_true[:, i]*K.log(y_pred[:, i]) + (1.0-y_true[:, i])*K.log(1.0-y_pred[:, i]\n",
    "        ), axis = -1))\n",
    "    loss = tf.stack(losses)\n",
    "    loss = K.mean(loss, axis=-1)\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        num_classes = int_shape(y_pred)[1]\n",
    "        true_positives = []\n",
    "        possible_positives = []\n",
    "        for i in range(num_classes):\n",
    "            true_positives.append(K.sum(K.round(K.clip(y_true[:, i] * y_pred[:, i], 0, 1))))\n",
    "            possible_positives.append(K.sum(K.round(K.clip(y_true[:, i], 0, 1))))\n",
    "        \n",
    "        true_positives = K.mean(tf.stack(true_positives), axis=-1) \n",
    "        possible_positives = K.mean(tf.stack(possible_positives), axis=-1) \n",
    "        \n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        num_classes = int_shape(y_pred)[1]\n",
    "        true_positives = []\n",
    "        predicted_positives = []\n",
    "        for i in range(num_classes):\n",
    "            true_positives.append(K.sum(K.round(K.clip(y_true[:, i] * y_pred[:, i], 0, 1))))\n",
    "            predicted_positives.append(K.sum(K.round(K.clip(y_pred[:, i], 0, 1))))\n",
    "        \n",
    "        true_positives = K.mean(tf.stack(true_positives), axis=-1) \n",
    "        predicted_positives = K.mean(tf.stack(predicted_positives), axis=-1) \n",
    "        \n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "import sklearn.metrics as sklm\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.losses_dev = []\n",
    "\n",
    "#     def average_auc(y_true, y_pred):\n",
    "#         auc = 0\n",
    "#         for i in range(y_true.shape[1]):\n",
    "#             auc += sklm.roc_auc_score(y_true, y_pred[:,i])\n",
    "#         return auc / y_true.shape[1]\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.losses_dev.append(logs.get('val_loss'))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.random.seed(seed)\n",
    "# estimator_baseline = KerasRegressor(build_fn=baseline_model, \n",
    "#                                     nb_epoch=1, batch_size=5, verbose=1)\n",
    "# results = cross_val_score(estimator_baseline, averages, Y_train, cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    X_indices = np.zeros(shape=(m, max_len))\n",
    "    for i in range(m):                               \n",
    "        sentence_words = X[i]\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if j >= max_len:\n",
    "                break\n",
    "            if w in word_to_index:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            else :\n",
    "                X_indices[i, j] = word_to_index['word']\n",
    "            j = j + 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, max_comment)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe \n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_len = len(word_to_index) + 1                  \n",
    "    emb_dim = word_to_vec[\"cucumber\"].shape[0]  \n",
    "    emb_matrix = np.zeros(shape=(vocab_len, emb_dim))\n",
    "    \n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec[word]\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from attention_decoder import AttentionDecoder\n",
    "#from attention_wrapper import Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_model(max_comment, num_classes, word_to_vec, word_to_index):\n",
    "    \"\"\"\n",
    "    Create the model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec -- dictionary mapping every word in a vocabulary into its n-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary \n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    sentence_indices = Input(shape=(max_comment,), dtype='float32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec, word_to_index)\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "#     X = embeddings\n",
    "#     attention_probs = Dense(max_comment, activation='softmax', name='attention_probs')(X)\n",
    "#     attention_mul = merge([X, attention_probs], output_shape=32, name='attention_mul', mode='mul')\n",
    "#     X = LSTM(32, input_shape=(max_comment, ), return_sequences = False)(attention_mul)\n",
    "#     X = Dropout(rate=0.5)(X)\n",
    "#     X = Dense(units=num_classes, activation='sigmoid')(X)\n",
    "    \n",
    "    X = LSTM(64, input_shape=(max_comment, ), return_sequences = True)(embeddings)\n",
    "    attention_probs = Dense(64, activation='softmax', name='attention_probs')(X)\n",
    "    attention_mul = merge([X, attention_probs], output_shape=32, name='attention_mul', mode='mul')\n",
    "    X = LSTM(32, input_shape=(max_comment, ), return_sequences = False)(attention_mul)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    X = Dense(units=num_classes, activation='sigmoid')(X)\n",
    "\n",
    "    #X = AttentionDecoder(64, num_classes, activation='sigmoid')(X)    \n",
    "#     X = Attention(LSTM(16, input_dim=num_dim, consume_less='mem', return_sequences=False))(X)   \n",
    "#     X = Dropout(rate=0.5)(X)\n",
    "#     X = Dense(units=num_classes, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs = [sentence_indices], outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mazhurin/keras/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Users/mazhurin/keras/lib/python3.6/site-packages/keras/legacy/layers.py:464: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only layers of same output shape can be merged using mul mode. Layer shapes: [(None, 500, 25), (None, 500, 500)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-85f7f09d568b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_to_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cucumber\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_RNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_comment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_RNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-953b952716c2>\u001b[0m in \u001b[0;36mrnn_model\u001b[0;34m(max_comment, num_classes, word_to_vec, word_to_index)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_comment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'attention_probs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mattention_mul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_probs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'attention_mul'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mul'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_comment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(inputs, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, name)\u001b[0m\n\u001b[1;32m    462\u001b[0m                             \u001b[0mnode_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                             \u001b[0mtensor_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                             name=name)\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, node_indices, tensor_indices, name)\u001b[0m\n\u001b[1;32m    115\u001b[0m             self._arguments_validation(layers, mode,\n\u001b[1;32m    116\u001b[0m                                        \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                                        node_indices, tensor_indices)\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m_arguments_validation\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 raise ValueError('Only layers of same output shape can '\n\u001b[1;32m    160\u001b[0m                                  \u001b[0;34m'be merged using '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' mode. '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                                  'Layer shapes: %s' % input_shapes)\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'cos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dot'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only layers of same output shape can be merged using mul mode. Layer shapes: [(None, 500, 25), (None, 500, 500)]"
     ]
    }
   ],
   "source": [
    "num_dim = word_to_vec[\"cucumber\"].shape[0]  \n",
    "model_RNN = rnn_model(max_comment, num_classes, word_to_vec, word_to_index)\n",
    "model_RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metrics = Metrics()\n",
    "fold_index = 0\n",
    "\n",
    "weights = np.sum(Y_train[folds[fold_index]['train']], axis=1)\n",
    "weights = np.divide(np.add(weights, 1), len(labels)+1)\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "model_RNN.compile(\n",
    "    loss=custom_loss,\n",
    "    #loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False), \n",
    "    metrics=[f1]\n",
    ")\n",
    "model_RNN.fit(X_train_indices[folds[fold_index]['train']], \n",
    "              Y_train[folds[fold_index]['train']], \n",
    "    epochs = 50, batch_size = 64, shuffle=True, verbose=True,\n",
    "    callbacks=[metrics],\n",
    "    sample_weight=weights,\n",
    "    validation_data=(\n",
    "        X_train_indices[folds[fold_index]['dev']], Y_train[folds[fold_index]['dev']]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.title(\"Learning Curves\")\n",
    "#plt.ylim((0.02, 0.16))\n",
    "plt.xlabel(\"Epocs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "epocs = [i+1 for i in range(len(metrics.losses))]\n",
    "plt.plot(epocs, metrics.losses, 'o-', color=\"g\", label=\"Training loss\")\n",
    "plt.plot(epocs, metrics.losses_dev, 'o-', color=\"r\",label=\"Dev loss\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predictions(probabilities, title):\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    fig.suptitle(title)\n",
    "    plt.autoscale(enable=False, axis='y')\n",
    "    width = 0.85\n",
    "    ind = np.arange(len(probabilities))\n",
    "    plt.bar(ind, probabilities, width=width, color='g')\n",
    "    plt.xticks(ind, labels)\n",
    "    \n",
    "def predict(text, model):\n",
    "    plot_predictions(model.predict(sentences_to_indices(\n",
    "        np.asarray([text.split()]),word_to_index, max_comment))[0], text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124577ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(\"Do you think you are smart? idiot\", model_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124577828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(\"I love you, my darling\", model_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-44396eaf7e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_RNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#y = model.predict(X_test_avg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1842\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1335\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keras/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y = model_RNN.predict(X_test_indices)\n",
    "#y = model.predict(X_test_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([\n",
    "    pd.DataFrame(id_test, columns=['id']), \n",
    "    pd.DataFrame(y, columns=labels)], axis=1)\n",
    "result = result.set_index('id')\n",
    "result = result.fillna(0.0)\n",
    "\n",
    "\n",
    "\n",
    "result.to_csv('./result/anton_10epocs_2_gru24d02gru12d02{}.csv'.format(datetime.now()), header=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:aind-dog]",
   "language": "python",
   "name": "conda-env-aind-dog-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
