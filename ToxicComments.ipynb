{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of Toxic Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle competition: [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation,GlobalMaxPool1D,Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load the data and separate into user ids, user comments and toxicity labels for each comment\n",
    "\"\"\"\n",
    "def read_comments(filename = ''):\n",
    "    comments = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "\n",
    "    with open (filename) as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "\n",
    "        header = True\n",
    "        for row in csvReader:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            ids.append(row[0])\n",
    "            s = row[1].translate(string.punctuation)\n",
    "            comments.append(s)          \n",
    "            if len(row) > 2:\n",
    "                classes = []\n",
    "                for i in range(2,8):\n",
    "                    classes.append(row[i])\n",
    "                labels.append(classes)\n",
    "\n",
    "    ids = np.asarray(ids)\n",
    "    X = np.asarray(comments)\n",
    "    Y = np.asarray(labels, dtype=int)\n",
    "\n",
    "    return ids, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "separate the two datasets into training and testing\n",
    "\"\"\"\n",
    "\n",
    "id_train, X_train, Y_train = read_comments('./data/train.csv')\n",
    "id_test, X_test, _ = read_comments('./data/test.csv')\n",
    "labels = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "\n",
    "max_comment = 0\n",
    "for i in range(X_train.shape[0]):                               \n",
    "    l = len(X_train[i].split())\n",
    "    if max_comment < l:\n",
    "        max_comment = l\n",
    "for i in range(X_test.shape[0]):                               \n",
    "    l = len(X_test[i].split())\n",
    "    if max_comment < l:\n",
    "        max_comment = l\n",
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5)\n",
    "# removed the random state as data does not get shuffled \n",
    "\n",
    "# folds = list()\n",
    "# for train_index, dev_index in kfold.split(X_train):\n",
    "#     folds.append({\n",
    "#         'train_index' : train_index,\n",
    "#         'dev_index' : dev_index,     \n",
    "#     })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed words and comments using GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the GloVe embedding. This will create a map $\\text{Gl}$ which assigns a vector in the vector space of embedded words  $\\cong \\mathbb{R}^{25}$ to each word in the GloVe corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A corpus of words is indexed (index of word called using word_to_index and conversely). A word is then embedded as a\n",
    "vector using word_to_vec\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def read_embeddings(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.24200000e+00,  -3.59800000e-01,   5.72850000e-01,\n",
       "         3.66750000e-01,   6.00210000e-01,  -1.88980000e-01,\n",
       "         1.27290000e+00,  -3.69210000e-01,   8.90800000e-02,\n",
       "         4.03390000e-01,   2.51300000e-01,  -2.55480000e-01,\n",
       "        -3.92090000e+00,  -1.11000000e+00,  -2.13080000e-01,\n",
       "        -2.38460000e-01,   9.53220000e-01,  -5.27500000e-01,\n",
       "        -7.80490000e-04,  -3.57710000e-01,   5.55820000e-01,\n",
       "         7.78690000e-01,   4.68740000e-01,  -7.78030000e-01,\n",
       "         7.83780000e-01])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index, index_to_word, word_to_vec = read_embeddings('./glove/glove.twitter.27B.25d.txt')\n",
    "word_to_vec[\"0.065561\"] = [ 0.39605,  -0.96669,   0.23706,  -0.41379,  -0.97006,   0.16601,  -1.292,\n",
    " -0.58989,   0.11632,  -1.365,    -0.27939,  -0.57222,  -0.97108,  -0.56319,\n",
    " -0.015263, -0.70465,  -0.13867 ,  1.0702 ,  -0.25557  , 0.25122,  -0.87755,\n",
    "  0.70999 ,  0.9118 ,  -0.30077, 0 ]\n",
    "\"word_to_vec[\"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fistfuckee.\n",
      "fuck.\n",
      "fuck.++You\n",
      "motherfucker!!!\n",
      "++fuck\n",
      "fuck.\n",
      "Assfuckers\n",
      "muthafucker.\n",
      "\"\"fucking\n",
      "++Muthafucka\n",
      "fuck.\n",
      "dumbfucks.\n",
      "muthafucka!\n",
      "mothafucka!\n",
      "clusterfucked\n",
      "\"\"clusterfucked\n",
      "motherfucker.\n",
      "\"\"fucking\n",
      "fuck...Before\n",
      "http://gawker.com/5636765/facebook-ceo-admits-to-calling-users-dumb-fucks+\n",
      "http://www.theweek.co.uk/technology/14625/are-users-%E2%80%98dumb-fucks%E2%80%99-trusting-data-facebook+\n",
      "http://tdh.me/zuckerberg-called-early-facebook-users-dumb-fucks-so-what/+\n",
      "http://anphicle.com/en/they-trust-me-dumb-fucks-facebook-ceo-mark-zuckerberg/+\n",
      "fucks\"\".\n",
      "fucks.++In\n",
      "Corpsefucking\n",
      "Corpsefucking\n",
      "Corpsefucking\n",
      "Corpsefucking\n",
      "changes++fuck\n",
      "motherfucker\"\"\n",
      "dumass.++fuck\n",
      "\"\"fucking\n",
      "fuckkk\n",
      "\"\"mindfuck\"\"\n",
      "fuck's\n",
      "Mindfuck\n",
      "fuck?\n",
      "fuckface.\n",
      "fuck.\n",
      "fuckin'\n",
      "motherfucker,\n",
      "bitch.++fuck\n",
      "lord/fuck\n",
      "fuckersItalic\n",
      "dumbfuck,\n",
      "fuck,\n",
      "fuck????\n",
      "fucking-ass\n",
      "++fuck\n",
      "Merchan-fucking-dise\n",
      "T-fucking-800.\n",
      "fuck...damn\n",
      "\"\"fuck\"\"\n",
      "\"\"fuck,\"\"\n",
      "\"\"fuck\"\"\n",
      "\"\"fuck\"\"\n",
      "\"\"fucking\"\")\n",
      "\"\"fuck\"\"\n",
      "\"\"fuck\"\"\n",
      "\"\"fuck\"\"\n",
      "\"\"fuck\"\"\n",
      "\"\"fuck\"\"\n",
      "fuck.\n",
      "'fuck'\n",
      "\"\"fuck.\"\"\n",
      ".++fuck\n",
      "fucktard.\n",
      "http://denverfuckedme.com/FY/viewtopic.php?f=7&t;=180&p;=365#p365++NOTICE!\n",
      "motherfucker?\n",
      "motherfucker}}\n",
      "++fuck\n",
      "Bg(fucking)\n",
      "\"\"fuck\n",
      "shitfucker+-me++Take\n",
      "dickfucker\n",
      "motherfucker!\n",
      "motherfucker,\n",
      "motherfucker.\n",
      "fuck?\"\n",
      "\"\"fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "bitches.fuck\n",
      "fuck......will\n",
      "animalfucker\n",
      "animalfucker.\n",
      "fuck?!?!++\"\"Germany\"\"\n",
      "fucker!!\n",
      "fuck.++You\n",
      "edits.++fuck\n",
      "fuck.++I\n",
      "fuck,\n",
      "dumbfuck.\n",
      "fucks.\n",
      "fuckhead!\n",
      "fucktard,\n",
      "motherfucker.\n",
      "fuck.+Should\n",
      "mother-fucker\n",
      "fuck.\n",
      "motherfucker,\n",
      "++fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+fuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuckfuck+computers\n",
      "\"\"fuck,\n",
      "fuckily\n",
      "\"\"fuck\n",
      "fuck,\n",
      "\"\"whoop-de-fucking-do\"\"?\n",
      "fucka!!!\n",
      "motherfuckers.++Typical\n",
      "fuckAN\n",
      "fucker,\n",
      "society...fuck\n",
      "fuck-sissy!!!!!!!!!++\n",
      "fuckin'\n",
      "fuck...\n",
      "Yamla_likes_to_fuck_babies_up_the_ass_wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww\n",
      "++fucks\n",
      "++fuck\n",
      "fuck!\n",
      "clusterfuck.\n",
      "fuck!\n",
      "fuck!\n",
      "Corspefucking\n",
      "'fuck'\n",
      "++fuck\n",
      "http://gawker.com/5636765/facebook-ceo-admits-to-calling-users-dumb-fucks+\n",
      "http://www.theweek.co.uk/technology/14625/are-users-%E2%80%98dumb-fucks%E2%80%99-trusting-data-facebook+\n",
      "http://tdh.me/zuckerberg-called-early-facebook-users-dumb-fucks-so-what/+\n",
      "http://anphicle.com/en/they-trust-me-dumb-fucks-facebook-ceo-mark-zuckerberg/+\n",
      "fucks\"\".\n",
      "fucks.++In\n",
      "fuck?\n",
      "fuck+Got\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "dumb-fucks,\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "fuck?\n",
      "motherfucker:++1.\n",
      "fuck!!!!!!\"\n",
      "fuck?\n",
      "fuck.+And\n",
      "fuck,\n",
      "fucker+Shut\n",
      "fucker.\n",
      "dumbfuck?\n",
      "\"\"fuck\n",
      "\"\"fuck\n",
      "\"\"fuck\n",
      "\"\"fuck\n",
      "fucki9ng\n",
      "++fuck\n",
      "fucker!126.12.157.168\n",
      "fuckstain.\n",
      "fuckhead!\n",
      "fuckturd!\n",
      "fucks,\n",
      "Motherfucking\n",
      "sick....fuckkkkk\n",
      "\"\"fuck\n",
      "fuckwit;++http://www.telegraph.co.uk/sport/othersports/boxing/11626770/James-DeGale-claims-super-middleweight-title-with-points-win-over-Andre-Dirrell-in-Boston.html++http://www.independent.co.uk/sport/general/boxing/andre-dirrell-vs-james-degale-on-saturday-degale-can-join-britains-great-list-of-supermiddleweight-champions-says-steve-bunce-10259295.html++FYI....boxing\n",
      "fuck!!\n",
      "'fuck'\n",
      "fuck,\n",
      "fuckyourself!!!\n",
      "motherfucker!!!!\n",
      "motherfucker...only\n",
      "fuck!ng\n",
      "fuck!ng\n",
      "fuck!ng\n",
      "fuck!ng\n",
      "'fuck'.\n",
      "'fuck'\n",
      "'fuck'\n",
      "fuckwad\"\"\n",
      "fuck.\n",
      "fuckknuckle?\n",
      "fuckknuckle?\n",
      "motherfucker!\n",
      "motherfuck,\n",
      "\"\"fucking\"\"\n",
      "\"\"fucking\"\"\n",
      "dumbfuck.\n",
      "fuck,\n",
      "motherfucker!!!\n",
      "motherfuckers?\n",
      "\"\"fuck\n",
      "fuckass.\n",
      "fuck,\n",
      "fuck.\n",
      "fuck.\n",
      "fuckin,ill\n",
      "\"\"fuck\n",
      "fuckin'\n",
      "fuck.\n",
      "fucked?\n",
      "Motherfucker\n",
      "fuck.\n",
      "bullshit+fuck\n",
      "fuckin'\n",
      "fuck's\n",
      "'fuck\n",
      "fuckwad.\n",
      "motherfucker\"\"\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin't\n",
      "\"\"fuck\n",
      "motherfucker?\n",
      "fuck\"\n",
      "much...fucked\n",
      "fuckmor\n",
      "++fuckBold\n",
      "fuck.\n",
      "fuckyouself\n",
      "fuckin'\n",
      "fuck.\n",
      "fat-fuck\n",
      "++fuck\n",
      "death++fuck\n",
      "\"\"fuckperezhilton.com\"\"\n",
      "\"\"fuck\n",
      "fucker,\n",
      "fuck.\n",
      "motherfucker.\n",
      "fucker.\n",
      "fucks,\n",
      "++fuck\n",
      "motherfucker.\n",
      "fuckwit!\n",
      "bitchfuck.\n",
      "fuckface.\n",
      "fuckfest\"\"\n",
      "fuck.\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fucker,\n",
      "me++Motherfucker++Ugh\n",
      "motherfucker.\n",
      "mohterfuck\n",
      "fuckwad.\"\n",
      "fuck!++Fuck\n",
      "fuckhead!\n",
      "fucker.\n",
      "fuck'ing\n",
      "fucker,\n",
      "whateverthefuck,++You\n",
      "fuck!\n",
      "Motherfucker\n",
      "Motherfucker,\n",
      "fuck,\n",
      "fucker,\n",
      "fuck,\n",
      "fist-fuckee\n",
      "dumbfuck.\n",
      "\"\"fuck\"\"\n",
      "fuckin'\n",
      "++fuck\n",
      "fuck?\n",
      "pigfuckers++There's\n",
      "fucktarded\n",
      "\"\"you-are-fucking-crazy-get-out-before-we-send-you-a-whole-jarful-of-cookies\n",
      "fucker.\n",
      "motherfucker.\n",
      "http://gawker.com/5636765/facebook-ceo-admits-to-calling-users-dumb-fucks+\n",
      "http://www.theweek.co.uk/technology/14625/are-users-%E2%80%98dumb-fucks%E2%80%99-trusting-data-facebook+\n",
      "http://tdh.me/zuckerberg-called-early-facebook-users-dumb-fucks-so-what/+\n",
      "http://anphicle.com/en/they-trust-me-dumb-fucks-facebook-ceo-mark-zuckerberg/+\n",
      "fucks\"\".\n",
      "fucks.++In\n",
      "fuck?\n",
      "mutherfuckng\n",
      "fuck,\n",
      "++fuck\n",
      "\"\"fucker\"\"\n",
      "motherfucker.\n",
      "\"\"fuckhead\"\"\n",
      "fuck.\n",
      "fuck.\n",
      "lord/fuck\n",
      "fucka!\n",
      "fuckwit!++Hu,you\n",
      "motherfucker!\n",
      "mother'fuckerer!!\n",
      "Deadfuck.\n",
      "\"\"fuck\n",
      "++fuck\n",
      "wikipedians++fuck\n",
      "motherfucker:++1.\n",
      "fuck!!!!!!\"\n",
      "fuckin'\n",
      "bitchfuck.\n",
      "fuckface.\n",
      "fuckyourself!!!++all\n",
      "\"+fuck\n",
      "fuckin'\n",
      "fucktard!!!!!!!\n",
      "fuckin'\n",
      "fuck.\n",
      "fuck.\n",
      "Motherfucker\n",
      "fuck?\n",
      "\"fucking\n",
      "fucknuckle\n",
      "fucknuckle\n",
      "motherfucker,\n",
      "fuck.\n",
      "fuck...damn\n",
      "fuckin'\n",
      "fuckin'\n",
      "MOtherfucker,\n",
      "fuckers,\n",
      "fuck,\n",
      "Motherfucker\n",
      "fuck-all\n",
      "motherfucker,\n",
      "shitfucker+-me\n",
      "fucked-ass\n",
      "fuck?!\n",
      "fuckwit!!!\n",
      "fuck,\n",
      "++fuck\n",
      "\"\"fuck\n",
      "Motherfucker,\n",
      "\"\"fuck\"\"\"\"\n",
      "ass-fuckers?\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "fuck,\n",
      "fuck.\n",
      "ISP...++yawn...++fuckin\n",
      "fuck.\n",
      "UTfuckin\n",
      "fucknig\n",
      "fuckyourself!!!\n",
      "fuck!\n",
      "motherfucker.\n",
      "++fuck\n",
      "\"\"fuck\n",
      "fucker...all\n",
      "motherfuckers.\n",
      "fuck!\n",
      "++youfuckingidiot\n",
      "motherfucker.\n",
      "sir...fucking\n",
      "fuck.\n",
      "fuck.\n",
      "fuck.\n",
      "discofucker,\n",
      "mothafucka.\n",
      "fuckin'\n",
      "++fuck??\n",
      "cow-fucking\n",
      "'fucker'\n",
      "fuck.\n",
      "fucker!\n",
      "'fucking',\n",
      "'fuck',\n",
      "asshole+fuck\n",
      "motherfucker,son\n",
      "fucked.\n",
      "fucker.\n",
      "fucker.\n",
      "fuck's\n",
      "brain++fuck\n",
      "motherfucker.\n",
      "motherfucker.\n",
      "\"\"fuck\n",
      "motherfucker:++1.\n",
      "fuck!!!!!!\"\n",
      "++pecker++fuckstick!!!++\n",
      "fuck-knuckle.\n",
      "fucker!!\n",
      "fuckin'\n",
      "fuckwit!\n",
      "fuckin'\n",
      "fuck.\n",
      "motherfucker,\n",
      "ass-fucked\n",
      ",otherfucker\n",
      "fuck:\n",
      "fuck?\n",
      "fuck,\n",
      "fuck.\n",
      "fucker.\n",
      "fucker?\n",
      "fuckface,\n",
      "fuckz.+[[Unblock}}\n",
      "motherfucker.\n",
      "\"\"fucking\n",
      "fuckwad.\n",
      "fuckers.\n",
      "fuck.\n",
      "motherfucker.\n",
      "fuckwit.\n",
      "motherfucker.\n",
      "fuckin'\n",
      "fuck++love\n",
      "fuck.\n",
      "xxxxxxMotherfucker+I\n",
      "fucker.\n",
      "fuckwads.\n",
      "fuckwads\n",
      "animalfucker\n",
      "muthafucker!\n",
      "fuck!120.62.16.147\n",
      "fuck?!\n",
      "\"\"fucking\n",
      "motherfucker.there\n",
      "++fuck\n",
      "fuck's\n",
      "LICKER+fuck\n",
      "fuck\"\"\n",
      "fucked,\n",
      "\"\"fuck\"\"\n",
      "you++fuck\n",
      "PEE-WEES++fuckan\n",
      "fucker.\n",
      "fuck,\n",
      "fuckhead.\n",
      "fuckelwad?\n",
      "fuck,\n",
      "fuck-it-I-don't-give-a-fuck\n",
      "fuck.\n",
      "fuck.\"\n",
      "motherfucker,\n",
      "motherfuckers++They\n",
      "fuck.+~~\n",
      "\"\"fucking\n",
      "fuckass!+You\n",
      "Yingfuck\n",
      "fuckin'\n",
      "fucknut.\n",
      "\":::fuck\n",
      "'fuck\n",
      "fuckyourselves+blaming\n",
      "everyfucking\n",
      "fucker,\n",
      "motherfucker!\n",
      "Mindfuck,\n",
      "clusterfuck,\n",
      "sockfuck.\n",
      "fuck.\n",
      "fucker.\n",
      "fucker.\n",
      "motherfucker++You\n",
      "fucker|\n",
      "fuckin'\n",
      "titt-fucking\n",
      "fucks,\n",
      "fuckwit.\n",
      "*fucking*\n",
      "fucks,\n",
      "fuck-head.\n",
      "fuckwit.\n",
      "fucker..Rajputs\n",
      "++fuck\n",
      "cousinfuckers\n",
      "motherfuckers.\n",
      "fuck?\n",
      "fuck's\n",
      "fuckers,\n",
      "Motherfucker\n",
      "motherfucker,\n",
      "++fucker\n",
      "fuck,\n",
      "motherfucker!\n",
      "Priest++motherfucker++shit+shit\n",
      "Motherfucker\n",
      "fuck'in\n",
      "fuck'in\n",
      "fuckiest\n",
      "fuckin'\n",
      "++fuck\n",
      "\"++fuck\n",
      "Motherfucker\n",
      "fucker.\n",
      "fucking-ass\n",
      "fuckwit!!!+Don;t\n",
      "mean?++fucking\n",
      "Pictures!!!++Motherfuckers\n",
      "fall++gfuck++good\n",
      "motehrfucker.\n",
      "fuck.\n",
      "fucktard.\n",
      "motherfucker,\n",
      "motherfucker,\n",
      "fuckin'\n",
      "fuck?\n",
      "fuck?\n",
      "fuck+Fucky\n",
      "fuck+Fucky\n",
      "fuck+Fucky\n",
      "fuck+Fucky\n",
      "fuck+Fucky\n",
      "fuck+Fuck\n",
      "fuck+Fucky\n",
      "fuck+Fucky\n",
      "fuck+Fucky\n",
      "fuck+Fucky\n",
      "fuck+Fucky\n",
      "motherfucker,\n",
      "Assfuckers\n",
      "++fuck\n",
      "fuck?\n",
      "fuck.\n",
      "motherfucker...\n",
      "++fuck\n",
      "Bamafuck\n",
      "is\"\"F-f-f-fuck\n",
      "fuckwit?\n",
      "un-fuck\n",
      ",fuck\n",
      "fuck.\n",
      "fucking.\n",
      "motherfuckin'\n",
      "fuckin'\n",
      "fucked.\n",
      "++fuck\n",
      "fuck's\n",
      "\"\"fuck\n",
      "fuckıng\n",
      "fuckıng\n",
      "fuck,\n",
      "fuckin'\n",
      "dog-fucking.++\"\n",
      "fucker.!!!!\n",
      "\"\"fuck\n",
      "fuckbags\n",
      "fuckwads.\n",
      "fuckwads\n",
      "\"\"fuck\n",
      "fuck,\n",
      "\"++fucking\n",
      "fuck!\n",
      "defuck+Your\n",
      "fuckability.\n",
      "mother-fucker\n",
      "fucker.\n",
      "Swagfuckingtastic.++\n",
      "fuck.\n",
      "fuckiest\n",
      "fuckin'\n",
      "fuckiest\n",
      "fuckin'\n",
      "fuckhead.\n",
      "asshole++fuck\n",
      "fist-fucking.\n",
      "motherfucker.\n",
      "+fuck\n",
      "(fucking\n",
      "fuckchop\n",
      "you+fuck\n",
      "motherfucker.\n",
      "fuck,\n",
      "fuck,\n",
      "fuck.\n",
      "fuck,\n",
      "\"\"fuck\n",
      "\"\"fuck\n",
      "motherfucker!!!\n",
      "fuck.\n",
      "motherfucker,\n",
      "fuck,\n",
      "\"\"fuck\"\"\n",
      "fucking...\n",
      "fuck!!!!!\n",
      "\"\"fuck\"\"\n",
      "fucker.\n",
      "fuck.\n",
      "fuckwit.\n",
      "fuckwqit\n",
      "++fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "cunt+fuck\n",
      "fuck.\n",
      "24-fucking-7\n",
      "motherfucker!!!!!!!!\"\"++Something\n",
      "fuck43\n",
      "fuck.\n",
      "fucktard.\n",
      "\"++Motherfucka\n",
      "motherfucker!!!\n",
      "fuckers.\n",
      "fucker's\n",
      "fuckmehorns,\n",
      "++fuck\n",
      "\"\"fuckism\"\"?\n",
      "fucktard.\n",
      "\"\"fuck\"\"\n",
      "fuck,\n",
      "shut-the-fuck-up\n",
      "fuck's\n",
      "fucker!!!!\n",
      "fucker.\n",
      "fuck'n\n",
      "fuck.\n",
      "fuckin'\n",
      "fuckin'\n",
      "++fuck\n",
      "fuck.\n",
      "fucker.++\"\n",
      "fuck,\n",
      "fuckin'\n",
      "site......fuck\n",
      "Huh?!?++fuck\n",
      "fuckin'\n",
      "me+Motherfucker+Ugh\"\n",
      "fuck.\n",
      "LifeBaka+fuck\n",
      "DIE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!fucker\n",
      "nonononononjesusfuckingchristno!\n",
      "\"\"fuck\"\"?\n",
      "fuckin'\n",
      "fucked.\n",
      "fuckers,\n",
      "fucker.\n",
      "fuck.\n",
      "++fuck\n",
      "++fuck\n",
      "fuckers!\n",
      "fucks.\n",
      "++fuck\n",
      "Al-fucking-mighty\n",
      "censored...++fuck\n",
      "fuck?\n",
      "++fuck\n",
      "++fuck\n",
      "++fuck\n",
      "animalfucker.\n",
      "fucktards??\n",
      "fuckface,\n",
      "fucker.\n",
      "++fuck\n",
      "\"\"fuck\"\"\n",
      "motherfuckers.\n",
      "fuck!\n",
      "fucktards??\n",
      "fuckfu*ker.\n",
      "fuckhead,+Contributions\n",
      "fuck.\n",
      "fuckwhits!!!\n",
      "fuck\"\";\n",
      "fucker!!!\n",
      "fucks,\n",
      "User:gofuckyourself\n",
      "fuck,\n",
      "\"\"fucking\"\"\n",
      "fuck-head,\n",
      "Pinkafuckup\n",
      "fucker.\n",
      "fucktard.\n",
      "fucker,\n",
      "fucktard.\n",
      "\"\"fuckin\"\"\n",
      "fuckup.\n",
      "fucktards.\n",
      "motherfucker,\n",
      "motherfucker.\n",
      "fucktard.\n",
      "me.++fuck\n",
      "child.fuck\n",
      "fuck.)\n",
      "fuckwhit\n",
      "fuckface?89.123.100.99\n",
      "\"\"fuck\"\"\n",
      "fuck!?+Computer:\n",
      "\"\"fuck\"\"\n",
      "shit-fucking\n",
      "fucks.\n",
      "Motherfucker\n",
      "Motherfucker,\n",
      "fuck,\n",
      "fucker,\n",
      "fuck,\n",
      "motherfuckers!\n",
      "\"\"fuck\"\"\n",
      "\"\"fuck\"\"\n",
      "\"\"fuck-sya\"\"\n",
      "fucktard.\n",
      "\"\"fuck\"\",\n",
      "\"\"fucked\n",
      "fuckin'\n",
      "fuckin'\n",
      "fucked.\n",
      "moth*rfucker,\n",
      "++fuck\n",
      "motherfucker.\n",
      "\"\"fuck\"\"\n",
      "fuck.\n",
      "Motherfucking\n",
      "fucks,\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "fucksex\n",
      "motherfucker!!!!\n",
      "mum!++fuck\n",
      "too++fuck\n",
      "++fuck\n",
      "++fuck\n",
      "don't-give-a-fuck\n",
      "(fucking\n",
      "motherfucker?\n",
      "motherfucker!!!!!!!!!!!!!\n",
      "motherfucker.\n",
      "fuck.\n",
      "motherfucker.\n",
      "fuck+Got\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuck+Got\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuck+Got\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuck+Got\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fuckin'\n",
      "fucked.\n",
      "\"\"fucking\n",
      "fuckwit.\n",
      "Motherfucking\n",
      "Motherfucker.+Example:\n",
      "Motherfucking\n",
      "fuckstick.\n",
      "fuck.\n",
      "motherfucker.\n",
      "fuck,\n",
      "\"\"fuck\n",
      "\"\"fucking\"\"\n",
      "\"\"fucking\"\"\n",
      "\"\"fuck\n",
      "\"\"fuck\n",
      "fuck.\n",
      "lord/fuck\n",
      "\"\"fuck\n",
      "\"\"fuck\n",
      "\"\"fuck\n",
      "fucker!!!\n",
      "what-so-fucking-ever!!!\n",
      "dickhead....fuck\n",
      "dickhead....fuck\n",
      "dickhead....fuck\n",
      "dickhead....fuck\n",
      "dickhead....fuck\n",
      "dickhead....fuck\n",
      "fuckish\n",
      "fucker!!\n",
      "fuck?\n",
      "(fuck\n",
      "Motherfucking\n",
      "fucked.\n",
      "fuckin'\n",
      "dumbfuck+The\n",
      "fuck's\n",
      "fuck!!!\n",
      "{{unblock-auto|...}fuck\n",
      "\"\"fuck\n",
      "fuck.\n",
      "website.++fuck\n",
      "\"\"clusterfucked\n",
      "motherfucker.\n",
      "fuck-sucking\n",
      "julianfuckton?\n",
      "dog-fucking?\n",
      "examples!+http://propagandapress.org/2007/02/21/fuck-bubba-by-saab-lofton/+http://propagandapress.org/2007/02/26/man-fuck-florida-talking-shit-about-cuba-saab-lofton/+http://activistsinlasvegas.blogspot.com/2006/12/rules-for-whites-by-saab-lofton.html\n",
      "motherfucker.\n",
      "Dumbfuck\n",
      "motherfucker.\n",
      "fuck.\n",
      "fuck-head.\n",
      "fuck.\n",
      "talk:Larryfuckstylinson\n",
      "muthafuckaa+How\n",
      "drugged/fucked\n",
      "fuckin'\n",
      "fuck?\n",
      "fucker.\n",
      "fuck,\n",
      "fucka..what\n",
      "bitch.....++fuck\n",
      "buhay..,fuck\n",
      "fuckwit.\n",
      "fucker.\n",
      "fucker!!!\n",
      "http://gawker.com/5636765/facebook-ceo-admits-to-calling-users-dumb-fucks+\n",
      "http://www.theweek.co.uk/technology/14625/are-users-%E2%80%98dumb-fucks%E2%80%99-trusting-data-facebook+\n",
      "http://tdh.me/zuckerberg-called-early-facebook-users-dumb-fucks-so-what/+\n",
      "http://anphicle.com/en/they-trust-me-dumb-fucks-facebook-ceo-mark-zuckerberg/+\n",
      "fucks\"\".\n",
      "fucks.++In\n",
      "fucka.+So\n",
      "fucka....\n",
      "fucking!\n",
      "fuck.\n",
      "fucks,\n",
      "\"\"fuck\n",
      "\"\"fuck\n",
      "\"\"fuck\n",
      "++fuckoff\n",
      "Motherfucked++you\n",
      "me++Motherfucker++Ugh\"\n",
      "motherfucker,\n",
      "fuck.\n",
      "fucker!\n",
      "pigfucks,\n",
      "fuck.\n",
      "motherfucker.\n",
      "\\fuck\n",
      "fucked.\n",
      "fucker.\"\n",
      "\"\"fuck\"\"\n",
      "fuckers!!!!\n",
      "fuckin'\n",
      "motherfucker,\n",
      "fuck!\n",
      "fucker.\n",
      "fuck's\n",
      "\"\"clusterfucked\n",
      "\"\"clusterfuck\"\"\n",
      "Ratfucking\n",
      "\"\"fuck\"\"?\n",
      "\"\"fuck\n",
      "\"\"fucking\"\"\n",
      "fuck!\n",
      "++fuck\n",
      "fucks,\n",
      "bullshit+fuck\n",
      "motherfucker.\n",
      "\"\"fucking\"\"\n",
      "\"\"fucking\"\"\n",
      "mo'fucka!!\"\n",
      "'fuck'\n",
      "'fuck'\n",
      "\"\"fuck\"\"\n",
      "fuck(that\n",
      "fuckwitz\n",
      "fuckitz\n",
      "fucker????\n",
      "fuck:++It\n",
      "++Motherfucker\n",
      "motherfucker.\n",
      "\"\"fuck\n",
      "motherfucker.\n",
      "fuck,\n",
      "Congrad-a-fucking-lations\n",
      "fuck,\n",
      "dumbfuck.\n",
      "http://gawker.com/5636765/facebook-ceo-admits-to-calling-users-dumb-fucks+\n",
      "http://www.theweek.co.uk/technology/14625/are-users-%E2%80%98dumb-fucks%E2%80%99-trusting-data-facebook+\n",
      "http://tdh.me/zuckerberg-called-early-facebook-users-dumb-fucks-so-what/+\n",
      "http://anphicle.com/en/they-trust-me-dumb-fucks-facebook-ceo-mark-zuckerberg/+\n",
      "fucks\"\".\n",
      "fucks.++In\n",
      "fuck,\n",
      "fucks,\n",
      "++fuck\n",
      "motherfucker,\n",
      "motherfuck.\n",
      "textfuck\n",
      "motherfucker,even\n",
      "++fuck\n",
      "motherfucker.\n",
      "fuck,\n",
      "'fucking'.\n",
      "fuck.\n",
      "(fucking)\n",
      "weeds.\"\"+fuck\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split each message into words , check if each word is present in corpus and if the message contains fuck\n",
    "\"\"\"\n",
    "\n",
    "for r in X_train:\n",
    "    words = r.split()\n",
    "    for w in words:\n",
    "        if w not in word_to_index:\n",
    "            if 'fuck' in w:\n",
    "                print(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the map $\\text{Gl}$ to create an embedding of each comment in the dataspace into $\\mathbb{R}^{25}$. This uses a function $\\Phi:\\mathbb{R}^{25\\times n}\\longrightarrow \\mathbb{R}^{25}$ which associates to $n$ embedded words a single embedded word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def embed_comment(comment,phi):\n",
    "    \"\"\"\n",
    "    convert a comment into a list of words and apply the function\n",
    "    \"\"\"\n",
    "    words = comment.lower().split()\n",
    "    embedded_comment = phi(words)\n",
    "    return embedded_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of a function, we take the mean of the embedded words in a comment (making sure every word indeed lies in the GloVe corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg(comment):\n",
    "    avg = np.zeros(shape=(len(word_to_vec['apple']), ))\n",
    "    for w in comment:\n",
    "        if w in word_to_vec:\n",
    "            avg += word_to_vec[w]\n",
    "    avg = avg / len(comment)\n",
    "    return avg  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it on a specific comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33236   ,  0.04180133, -0.08893267, -0.29773667, -0.34060667,\n",
       "        0.42482   ,  1.7229    , -0.096961  , -0.93848667,  0.09561933,\n",
       "       -0.32179667,  0.456702  , -5.20073333, -0.20553333, -0.38219333,\n",
       "       -0.10963433,  0.25742333, -0.99007333, -0.17248333, -0.21952667,\n",
       "        0.24352767,  0.196192  , -0.36706667,  0.44628   , -0.41614   ])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_comment(\"you are nice\",avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_comment(comment, word_to_vec):\n",
    "    \"\"\"\n",
    "    Converts a comment into a list of words. \n",
    "    Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    comment -- string\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary \n",
    "    into its n-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (n,)\n",
    "    \"\"\"\n",
    "    words = comment[0].lower().split()\n",
    "    avg = np.zeros(shape=(len(word_to_vec['apple']), ))\n",
    "    for w in words:\n",
    "        if w in word_to_vec:\n",
    "            avg += word_to_vec[w]\n",
    "    avg = avg / len(words)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21767 ,  0.19018 , -0.27414 ,  0.69654 ,  0.12748 ,  0.83719 ,\n",
       "       -1.2804  ,  3.8718  , -0.96223 , -1.1195  ,  0.985   , -2.4167  ,\n",
       "       -2.9994  ,  0.017624,  1.3301  ,  0.48203 , -0.19386 ,  0.09823 ,\n",
       "        1.2263  ,  0.80212 ,  0.48846 , -0.98181 ,  0.53096 ,  0.4342  ,\n",
       "        0.67874 ])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_comment(\"you are nice\",word_to_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we gather all embedded comments in a single array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "averages = list()\n",
    "for c in X_train:\n",
    "    averages.append(average_comment(c, word_to_vec))\n",
    "averages = np.asarray(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106912"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learning_curves(model):\n",
    "    #plot the learning curve for the accuracy\n",
    "        #plot the accuracy on the training set\n",
    "        plt.plot(model.history['acc'])\n",
    "        #plot the accuracy on the dev set\n",
    "        plt.plot(model.history['val_acc'])\n",
    "        #describe the labels\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'dev'], loc='upper left')\n",
    "        plt.show()\n",
    "    # plot the learning curve for the loss\n",
    "        #plot the loss on the training set\n",
    "        plt.plot(model.history['loss'])\n",
    "        #plot the loss on the dev set\n",
    "        plt.plot(model.history['val_loss'])\n",
    "        #describe the labels\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'dev'], loc='upper left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "compile a Keras model and fit it according to a certain optimizer, loss, epochs and batch size\n",
    "\"\"\"\n",
    "\n",
    "def comp_fit(model,optim,loss,epochs,bs):\n",
    "    model.compile(optimizer=optim, loss=loss, metrics=['accuracy'])\n",
    "    history=model.fit(X_train, Y_train, validation_data=(X_dev, Y_dev), epochs=epochs, batch_size=bs,  verbose=1)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes in a 25-dim vector computed as $\\frac{1}{n}\\sum_{w\\in c}\\text{Gl}(w) $ where $n$ is the length of the comment $c$ and performs logistical regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "declare the training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim = 'adam'\n",
    "loss = 'binary_crossentropy'\n",
    "epochs = 4\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "declare the training and dev-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_train = Y_train\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(averages, labels_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build, compile and fit the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(num_dim=25, num_labels=6):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_labels, input_shape=(num_dim,), kernel_initializer='normal', activation='sigmoid'))\n",
    "    history = comp_fit(model,optim,loss,epochs,bs)\n",
    "    learning_curves(history)\n",
    "    return baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 106912 samples, validate on 52659 samples\n",
      "Epoch 1/4\n",
      "106912/106912 [==============================] - 77s - loss: 0.1383 - acc: 0.9631 - val_loss: 0.1355 - val_acc: 0.9629\n",
      "Epoch 2/4\n",
      "106912/106912 [==============================] - 78s - loss: 0.1335 - acc: 0.9635 - val_loss: 0.1348 - val_acc: 0.9629\n",
      "Epoch 3/4\n",
      "106912/106912 [==============================] - 79s - loss: 0.1329 - acc: 0.9635 - val_loss: 0.1348 - val_acc: 0.9630\n",
      "Epoch 4/4\n",
      "106912/106912 [==============================] - 79s - loss: 0.1326 - acc: 0.9635 - val_loss: 0.1344 - val_acc: 0.9630\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGooAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29de18f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKEhERCQmChIREYmJgkRERGLy/wF/5pZC3cwCJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x36ae55128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.baseline_model>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(num_dim=25, num_labels=6):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_labels, input_shape=(num_dim,), kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        #loss=custom_loss,\n",
    "        optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "159571/159571 [==============================] - 14s - loss: 0.1492 - acc: 0.9622    \n",
      "Epoch 2/4\n",
      "159571/159571 [==============================] - 15s - loss: 0.1351 - acc: 0.9633    \n",
      "Epoch 3/4\n",
      "159571/159571 [==============================] - 13s - loss: 0.1341 - acc: 0.9633    \n",
      "Epoch 4/4\n",
      "159571/159571 [==============================] - 13s - loss: 0.1336 - acc: 0.9633    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ad2afe10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(averages, Y_train, epochs=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-40398fd8f90b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearning_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-22cea2ac6018>\u001b[0m in \u001b[0;36mlearning_curves\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#plot the learning curve for the accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m#plot the accuracy on the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m#plot the accuracy on the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "learning_curves(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from keras.backend import int_shape\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "_EPSILON = K.epsilon()\n",
    "    \n",
    "def custom_loss(y_true, y_pred):\n",
    "    losses = []\n",
    "    y_pred = K.clip(y_pred, _EPSILON, 1.0-_EPSILON)\n",
    "    num_classes = int_shape(y_pred)[1]\n",
    "    for i in range(num_classes):\n",
    "        losses.append(K.mean(-(\n",
    "            y_true[:, i]*K.log(y_pred[:, i]) - (1-y_true[:, i])*K.log(1-y_pred[:, i])\n",
    "        ), axis = -1))\n",
    "    loss = tf.stack(losses)\n",
    "    loss = K.mean(loss, axis=-1)\n",
    "        \n",
    "    return loss\n",
    "    #return tf.convert_to_tensor(losses, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "127656/127656 [==============================] - 73s - loss: 0.1383 - acc: 0.9631    \n",
      "Epoch 2/10\n",
      "127656/127656 [==============================] - 69s - loss: 0.1337 - acc: 0.9635    \n",
      "Epoch 3/10\n",
      "127656/127656 [==============================] - 67s - loss: 0.1331 - acc: 0.9635    \n",
      "Epoch 4/10\n",
      "127656/127656 [==============================] - 67s - loss: 0.1328 - acc: 0.9635    \n",
      "Epoch 5/10\n",
      "127656/127656 [==============================] - 65s - loss: 0.1326 - acc: 0.9635    \n",
      "Epoch 6/10\n",
      "127656/127656 [==============================] - 70s - loss: 0.1325 - acc: 0.9635    \n",
      "Epoch 7/10\n",
      "127656/127656 [==============================] - 68s - loss: 0.1324 - acc: 0.9635    \n",
      "Epoch 8/10\n",
      "127656/127656 [==============================] - 68s - loss: 0.1324 - acc: 0.9635    \n",
      "Epoch 9/10\n",
      "127656/127656 [==============================] - 67s - loss: 0.1323 - acc: 0.9635    \n",
      "Epoch 10/10\n",
      "127656/127656 [==============================] - 67s - loss: 0.1323 - acc: 0.9635    \n",
      "31730/31915 [============================>.] - ETA: 0sEpoch 1/10\n",
      "127657/127657 [==============================] - 68s - loss: 0.1386 - acc: 0.9631    \n",
      "Epoch 2/10\n",
      "127657/127657 [==============================] - 74s - loss: 0.1339 - acc: 0.9633    \n",
      "Epoch 3/10\n",
      "127657/127657 [==============================] - 66s - loss: 0.1333 - acc: 0.9633    \n",
      "Epoch 4/10\n",
      "127657/127657 [==============================] - 66s - loss: 0.1330 - acc: 0.9633    \n",
      "Epoch 5/10\n",
      "127657/127657 [==============================] - 66s - loss: 0.1328 - acc: 0.9633    \n",
      "Epoch 6/10\n",
      "127657/127657 [==============================] - 66s - loss: 0.1327 - acc: 0.9633    \n",
      "Epoch 7/10\n",
      "127657/127657 [==============================] - 67s - loss: 0.1326 - acc: 0.9633    \n",
      "Epoch 8/10\n",
      "127657/127657 [==============================] - 67s - loss: 0.1326 - acc: 0.9633    \n",
      "Epoch 9/10\n",
      "127657/127657 [==============================] - 66s - loss: 0.1325 - acc: 0.9633    \n",
      "Epoch 10/10\n",
      "127657/127657 [==============================] - 67s - loss: 0.1324 - acc: 0.9633    \n",
      "31825/31914 [============================>.] - ETA: 0sEpoch 1/10\n",
      "127657/127657 [==============================] - 72s - loss: 0.1389 - acc: 0.9627    \n",
      "Epoch 2/10\n",
      "127657/127657 [==============================] - 68s - loss: 0.1339 - acc: 0.9633    \n",
      "Epoch 3/10\n",
      "127657/127657 [==============================] - 68s - loss: 0.1333 - acc: 0.9633    \n",
      "Epoch 4/10\n",
      "127657/127657 [==============================] - 68s - loss: 0.1330 - acc: 0.9633    \n",
      "Epoch 5/10\n",
      "127657/127657 [==============================] - 66s - loss: 0.1328 - acc: 0.9633    \n",
      "Epoch 6/10\n",
      "127657/127657 [==============================] - 69s - loss: 0.1327 - acc: 0.9633    \n",
      "Epoch 7/10\n",
      "127657/127657 [==============================] - 77s - loss: 0.1326 - acc: 0.9633    \n",
      "Epoch 8/10\n",
      "101130/127657 [======================>.......] - ETA: 16s - loss: 0.1332 - acc: 0.9631"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-444169ae9617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m estimator_baseline = KerasRegressor(build_fn=baseline_model, \n\u001b[1;32m      3\u001b[0m                                     nb_epoch=1, batch_size=5, verbose=1)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_baseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results: %.2f (%.2f) MSE\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    936\u001b[0m                 ' to a larger type (e.g. int64).')\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m           \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \"\"\"Convert the input to an array.\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimator_baseline = KerasRegressor(build_fn=baseline_model, \n",
    "                                    nb_epoch=1, batch_size=5, verbose=1)\n",
    "results = cross_val_score(estimator_baseline, averages, Y_train, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    X_indices = np.zeros(shape=(m, max_len))\n",
    "    for i in range(m):                               \n",
    "        sentence_words = X[i].lower().split()\n",
    "        if len(sentence_words) > max_len:\n",
    "            print (\"Too many words:\", len(sentence_words))\n",
    "            continue\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            if w in word_to_index:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            else :\n",
    "                X_indices[i, j] = word_to_index['word']\n",
    "            j = j + 1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, max_comment)\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe \n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_len = len(word_to_index) + 1                  \n",
    "    emb_dim = word_to_vec[\"cucumber\"].shape[0]  \n",
    "    emb_matrix = np.zeros(shape=(vocab_len, emb_dim))\n",
    "    \n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec[word]\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_model(input_shape, num_classes, word_to_vec, word_to_index):\n",
    "    \"\"\"\n",
    "    Create the model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec -- dictionary mapping every word in a vocabulary into its n-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary \n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    sentence_indices = Input(shape=input_shape, dtype='float32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec, word_to_index)\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    X = Bidirectional(LSTM(18, return_sequences = False))(embeddings)\n",
    "    X = Dropout(rate=0.1)(X)\n",
    "#     X = LSTM(8, return_sequences = False)(X)\n",
    "#     X = Dropout(rate=0.2)(X)\n",
    "    X = Dense(units=50, activation='relu')(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "    X = Dense(units=num_classes, activation='sigmoid')(X)\n",
    "    model = Model(inputs = [sentence_indices], outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2321)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 2321, 25)          29837875  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 36)                6336      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                1850      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 29,846,367.0\n",
      "Trainable params: 8,492.0\n",
      "Non-trainable params: 29,837,875.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_RNN = rnn_model((max_comment,), num_classes, word_to_vec, word_to_index)\n",
    "model_RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_RNN.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 63104/159571 [==========>...................] - ETA: 7041s - loss: 0.1488 - acc: 0.9584"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-7b8efe4b444f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_RNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/aind-dog/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_RNN.fit(X_train_indices, Y_train, epochs = 2, batch_size = 128, shuffle=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_predictions(probabilities, title):\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    fig.suptitle(title)\n",
    "    plt.autoscale(enable=False, axis='y')\n",
    "    width = 0.85\n",
    "    ind = np.arange(len(probabilities))\n",
    "    plt.bar(ind, probabilities, width=width, color='g')\n",
    "    plt.xticks(ind, labels)\n",
    "    \n",
    "def predict(text, model):\n",
    "    plot_predictions(model.predict(sentences_to_indices(\n",
    "        np.asarray([text]),word_to_index, max_comment))[0], text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3862d0860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(\"Do you think you are smart? idiot\", model_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1509509  0.00603852 0.07105798 0.0083426  0.06707279 0.00881005]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29a73cc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(\"I love you, my darling\", model_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = model_RNN.predict(X_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([\n",
    "    pd.DataFrame(id_test, columns=['id']), \n",
    "    pd.DataFrame(y, columns=labels)], axis=1)\n",
    "result = result.set_index('id')\n",
    "result = result.fillna(0.0)\n",
    "result.to_csv('./result/anton_rnn_{}.csv'.format(datetime.now()), header=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:aind-dog]",
   "language": "python",
   "name": "conda-env-aind-dog-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
